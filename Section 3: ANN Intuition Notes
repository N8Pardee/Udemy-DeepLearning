The Neuron:
  - 1st step: neuron (node) takes in input values with weights (synapse) and produces output signal
  - 2nd step: takes weighted sum of all input values. Summation i = 1 to m of weight_i * x_i
  - 3rd step: neuron will or will not process and pass on the output signal.

  x1 \
  x2 -  neuron -- y
  x3 /

  - We need to standardized or normalize our variables, meaning mean of zero or variance 1
  - normalize by subtracting minimum value and dividing maximum - minimum to find the range of values between 0 to 1
  - values will go into NN and influenced by weights which is why it is important to standardize the variables

  addnl reading Efficient BackProp by Yann LeCun (1998)
    Link: http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf

  -oputput variables can be continuous(price), Binary(yes/no),categorical
  -single observation from input (one row from dataset) and on ouput side there is a single observation for that same row. Same Observation

  -Synapses are assigned weights.
  -weights are crucial for ANN. Weights are how the NN learns. Gradient, Descendt, backprop come into play here

Activation Function:
-4 different types of activation functions

Threshold function:
  -x axis is weighted sum of inputs and y axis is values from 0 to 1
  - if the value is less than 0, then threshold fn passes on 0, if >= 0 then it passes a 1. 
  -Either yes or no, 1 or 0, etc

Sigmoid function:
- x axis is sum of weighted inputs
- between 0 or 1
-y axis is 1/(1+e^-x) where x is the value of the weighted sums
- used in logistic regression
- does not have "kinks" in its curve, has a smoother curve.
- useful in the output layer or when predicting probability

Rectifier Function:
-one of the most optimal functions in ANN
- goes all the way to 0 then gradually progresses as the input value increases
-one of most used
- y axis is = max(x,0)

-Hyperbolic Tangent:
-values go from 0 to -1 and 0 to 1
- y axis is = (1-e^-2x)/(1+e^-2x)

addtl reading: Deep Sparse rectifier neural networks by Xavier Glorol (2011)

Question 1:
Assuming the DV is binary (y= 0 or 1) which function would you use?
Answer: Threshold or Sigmoid. Sigmoid activation bc of probability of 0 or 1 and threshold bc output is 0 or 1

Example 2:
3 input layers, 4 hidden layers, 1 output layer. We would use rectifier function for the hidden layer and the
sigmoid function for the output layer to produce a probability











  
  
